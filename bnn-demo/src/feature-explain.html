<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>功能解析 | 二值神经网络实现指南</title>
    <style>
        body { background: #f8fafc; color: #1e293b; font-family: 'Segoe UI', system-ui, sans-serif; margin: 0; }
        .container { max-width: 700px; margin: 3rem auto; background: #fff; border-radius: 16px; box-shadow: 0 4px 24px rgba(0,0,0,0.07); padding: 2.5rem 2rem; }
        h1 { font-size: 2rem; color: #6366f1; margin-bottom: 1.2rem; }
        .desc { font-size: 1.1rem; color: #475569; margin-bottom: 2rem; }
        .back { display: inline-block; margin-bottom: 2rem; color: #6366f1; text-decoration: none; font-size: 1rem; }
        .icon { font-size: 2.5rem; margin-bottom: 1rem; }
    </style>
</head>
<body>
    <div class="container">
        <a href="index.html" class="back">← 返回主页</a>
        <div id="feature-content"></div>
    </div>
    <script>
    // 功能解释内容
    const featureMap = {
        core: {
            icon: '🧠',
            title: '二值化核心机制',
            desc: `
            <p><strong>原理简介：</strong><br>
            二值化神经网络（BNN）的核心在于将权重和激活值限制为+1或-1。通过自定义的Binarize类，前向传播时采用Sign函数将输入映射为±1，极大减少了模型的存储和计算需求。反向传播则采用直通估计器（STE），允许梯度在不可导点近似传递，从而保证网络可训练。</p>
            <p><strong>技术细节：</strong><br>
            <ul>
                <li>权重/激活二值化：<span style="color:#6366f1">w ∈ {+1, -1}</span>，<span style="color:#6366f1">a ∈ {+1, -1}</span></li>
                <li>STE（Straight-Through Estimator）原理：<br>
                    <span style="background:#f8fafc;padding:2px 6px;border-radius:4px;">forward: y = sign(x)</span><br>
                    <span style="background:#f8fafc;padding:2px 6px;border-radius:4px;">backward: dy/dx ≈ 1(|x|≤1)</span>
                </li>
                <li>常用激活函数：Sign、HardTanh</li>
            </ul>
            </p>
            <p><strong>经典论文与资料：</strong><br>
                <a href="https://arxiv.org/abs/1602.02830" target="_blank">Binarized Neural Networks (BNN)</a> &nbsp;|&nbsp;
                <a href="https://arxiv.org/abs/1603.05279" target="_blank">XNOR-Net: ImageNet Classification Using Binary Convolutional Neural Networks</a> &nbsp;|&nbsp;
                <a href="https://zhuanlan.zhihu.com/p/266134324" target="_blank">知乎科普：二值神经网络原理</a>
            </p>
            <p><strong>应用案例：</strong><br>
            <ul>
                <li>嵌入式AI芯片（如Kendryte K210）上的超低功耗推理</li>
                <li>移动端实时图像识别</li>
                <li>物联网终端的边缘智能</li>
            </ul>
            </p>
            <p><strong>图示：</strong><br>
                <span style="font-family:monospace;font-size:1.1em;">输入 → <b>Sign</b> → ±1 → <b>二值卷积/全连接</b> → 输出</span>
            </p>
            <p style="color:#6366f1;font-size:0.98em;">二值化极大压缩模型体积，推理速度提升10~50倍，但需注意精度损失。</p>
            `
        },
        structure: {
            icon: '🛠️',
            title: '网络结构设计',
            desc: `
            <p><strong>结构特点：</strong><br>
            本BNN采用类似VGG的堆叠式结构，卷积层和全连接层均用自定义的二值化版本（BinarizedConv2d/BinarizedLinear）替代。激活函数选用Hardtanh，输出范围严格限制在[-1,1]，有助于后续二值化。</p>
            <ul>
                <li>每层后紧跟HardTanh，减少量化误差</li>
                <li>可引入残差结构（如BinaryResNet）提升表达力</li>
                <li>支持多比特量化混合（如DoReFa-Net）</li>
            </ul>
            <p><strong>经典论文与资料：</strong><br>
                <a href="https://arxiv.org/abs/1602.02830" target="_blank">Binarized Neural Networks</a> &nbsp;|&nbsp;
                <a href="https://arxiv.org/abs/1707.07170" target="_blank">DoReFa-Net: Training Low Bitwidth CNNs</a> &nbsp;|&nbsp;
                <a href="https://arxiv.org/abs/1708.04788" target="_blank">Bi-Real Net: Enhancing the Performance of 1-bit CNNs</a>
            </p>
            <p><strong>应用案例：</strong><br>
                <ul>
                    <li>图像分类（如CIFAR-10、ImageNet）</li>
                    <li>目标检测（如YOLO-BNN）</li>
                </ul>
            </p>
            <p><strong>结构示意：</strong><br>
                <span style="font-family:monospace;">输入 → [二值卷积+HardTanh] × N → 展平 → [二值全连接+HardTanh] × M → 输出</span>
            </p>
            `
        },
        training: {
            icon: '⚡',
            title: '训练优化策略',
            desc: `
            <p><strong>优化方法：</strong><br>
            采用Adam优化器，兼顾收敛速度和稳定性。损失函数选用交叉熵，适合多分类任务。训练过程中每个epoch后进行测试，实时监控模型性能。</p>
            <ul>
                <li>数据增强（如Cutout、Mixup）提升泛化</li>
                <li>知识蒸馏辅助二值网络训练</li>
                <li>分布重塑、比例因子等提升精度</li>
            </ul>
            <p><strong>经典论文与资料：</strong><br>
                <a href="https://arxiv.org/abs/1904.02823" target="_blank">IR-Net: Improving Binarized Neural Networks</a> &nbsp;|&nbsp;
                <a href="https://arxiv.org/abs/1512.03385" target="_blank">Distilling the Knowledge in a Neural Network</a> &nbsp;|&nbsp;
                <a href="https://pytorch.org/docs/stable/optim.html" target="_blank">PyTorch官方优化器文档</a>
            </p>
            <p><strong>应用案例：</strong><br>
                <ul>
                    <li>工业缺陷检测中的高效模型训练</li>
                    <li>边缘设备的快速模型迭代</li>
                </ul>
            </p>
            `
        },
        hardware: {
            icon: '🚀',
            title: '硬件加速支持',
            desc: `
            <p><strong>加速原理：</strong><br>
            BNN模型自动检测CUDA设备，优先使用GPU加速。二值化参数可通过位运算（如XNOR、bitcount）实现高效推理，理论上可达58倍加速。</p>
            <ul>
                <li>XNOR/AND/OR等位运算替代浮点乘法</li>
                <li>支持FPGA/NPU/嵌入式GPU等多平台</li>
                <li>ONNX/TorchScript导出便于跨平台部署</li>
            </ul>
            <p><strong>经典论文与资料：</strong><br>
                <a href="https://arxiv.org/abs/1603.05279" target="_blank">XNOR-Net: ImageNet Classification Using Binary Convolutional Neural Networks</a> &nbsp;|&nbsp;
                <a href="https://onnxruntime.ai/" target="_blank">ONNX Runtime</a> &nbsp;|&nbsp;
                <a href="https://pytorch.org/docs/stable/jit.html" target="_blank">TorchScript官方文档</a>
            </p>
            <p><strong>应用案例：</strong><br>
                <ul>
                    <li>智能摄像头的本地人脸识别</li>
                    <li>FPGA加速的实时视频分析</li>
                </ul>
            </p>
            <p><strong>加速示意：</strong><br>
                <span style="font-family:monospace;">二值输入 ⊕ 二值权重 → bitcount → 累加 → 输出</span>
            </p>
            `
        },
        performance: {
            icon: '📊',
            title: '性能表现',
            desc: `
            <p><strong>实验结果：</strong><br>
            在MNIST数据集上，BNN可实现约95%的测试准确率，模型大小仅为原始浮点模型的1/32，推理速度大幅提升。</p>
            <ul>
                <li>ImageNet上XNOR-Net精度可达51.2%</li>
                <li>模型体积压缩10~32倍</li>
                <li>推理速度提升10~50倍</li>
            </ul>
            <p><strong>经典论文与资料：</strong><br>
                <a href="https://arxiv.org/abs/1603.05279" target="_blank">XNOR-Net论文</a> &nbsp;|&nbsp;
                <a href="https://paperswithcode.com/task/binarized-neural-networks" target="_blank">Papers With Code: Binarized Neural Networks</a>
            </p>
            <p><strong>应用案例：</strong><br>
                <ul>
                    <li>移动端手写数字识别</li>
                    <li>超低功耗物联网终端</li>
                </ul>
            </p>
            <p><strong>性能对比图示：</strong><br>
                <span style="font-family:monospace;">浮点模型(32MB) → <b>BNN(1MB)</b>，推理速度提升数十倍</span>
            </p>
            `
        }
    };
    // 获取URL参数
    function getQueryParam(name) {
        const url = new URL(window.location.href);
        return url.searchParams.get(name);
    }
    const feature = getQueryParam('feature');
    const content = featureMap[feature] || { title: '未知功能', desc: '<p>未找到对应的功能解释。</p>', icon: '❓' };
    document.getElementById('feature-content').innerHTML = `
        <div class="icon">${content.icon}</div>
        <h1>${content.title}</h1>
        <div class="desc">${content.desc}</div>
    `;
    </script>
</body>
</html> 